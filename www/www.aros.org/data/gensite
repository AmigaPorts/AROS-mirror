#!/usr/bin/env python

'''Generate the AROS WWW site.

The process works like this:

- First, the contents of all manually created pages is converted to
partial HTML. Manually created pages are pages where the content comes
from some kind of source file. Partial HTML is HTML which goes into
the "meat" part of the page and which can contain placeholders, namely
VHREFs or virtual HRefs like this:

    <a vhref="Documentation">

These will be replaced by normal hrefs which point to the document
which is known as "Documentation".
'''

import glob
from util import *

def genDocumentation ():
    page = PageMeat ('Documentation', 'documentation.html')
    page.append (
	Heading (2, 'Documentation'),
	Paragraph ('Please choose a link to the left'),
    )
    page.write ()
    #n = mainLinks2.getNode (page)
    #print "n=",n
    #print "n.parent=",n.parent
    #print "n.parent.parent=",n.parent.parent
    return page

#print 'root=',mainLinks2.root
#pm = PageMeat ('Test1', 'test1.html')
#pm.append (Text ('Test1'))
#pm.write ()
#pm = PageMeat ('Test2', 'test1.html')
#pm.append (Text ('Test2'))
#pm.write ()
#pm = PageMeat ('Test2/Test', 'test1.html')
#pm.append (Text ('Test2'))
#pm.write ()
#print 'root.order=',mainLinks2.root.order
#node = mainLinks2.getNode (pm)
#print 'node=',node
#print 'node.parent=',node.parent
#print 'node.parent.parent=',node.parent.parent

def genScreenshots ():
    '''Create a page with screenshots.'''

    page = PageMeat ('Screenshots', 'screenshots.html')

    # First, the pictures of AROS developers, etc.
    tn1 = Thumbnail ('pics/developers/Digulla-2.jpg')
    tn2 = Thumbnail ('pics/developers/Digulla-1.jpg')
    tn3 = Thumbnail ('pics/developers/nlorentz.jpg')
    tn4 = Thumbnail ('pics/developers/periksson.jpg')
    tn5 = Thumbnail ('pics/developers/sheutling.jpg')
    page.append (
	Href ('#PicturesAroundAROS', '1. Pictures around AROS'),
	BR (),
	Href ('#Screenshots', '2. Screenshots'),
	BR (),
	BR(), HR(), BR(),
	Name ('PicturesAroundAROS'),
	Heading (2, '1. Pictures around AROS'),
	Paragraph ('If you ever wanted to know what Aaron "Optimizer" Digulla'
	    ' looks like, here are two pictures:'),
	ThumbnailTable (tn1, tn2),
	Paragraph ('Picture of Nils Henrik Lorentzen:'),
	ThumbnailTable (tn3),
	Paragraph ('Picture of Peter Eriksson:'),
	ThumbnailTable (tn4),
	Paragraph ('Picture of Sebastian Heutling:'),
	ThumbnailTable (tn5),
	Paragraph ('Hopefully, more pictures of AROS developers will'
	    ' show up here :-)'),
	Name ('Screenshots'),
	Heading (2, '2. Screenshots'),
    )

    page.linksToFix.append (tn1.href)
    page.imagesToFix.append (tn1.img)
    page.linksToFix.append (tn2.href)
    page.imagesToFix.append (tn2.img)
    page.linksToFix.append (tn3.href)
    page.imagesToFix.append (tn3.img)

    def processDir (dir, page=page):
	'''Read a directory and put all pictures in it into ThumbnailTables.
	The name of the directory must be YYYYMMDD.'''
	str = os.path.basename (dir)
	date = '%d.%d.%d' % (
	    int (str[6:8]),
	    int (str[4:6]),
	    int (str[0:4]),
	)
	fh = open (os.path.join (dir, 'README'), 'r')
	text = fh.read ()
	fh.close ()
	
	list = [
	    Paragraph (RawText ('%s - %s' % (date, text))),
	]
	files = glob.glob (os.path.join (dir, "*.*"))
	files.sort ()
	pics = []
	for file in files:
	    if file[-4:] == '.txt' or string.find (file, '_mini.') != -1:
		continue

	    tn = Thumbnail (
		os.path.join (
		    screenshoturl,
		    str,
		    os.path.basename (file)
		)
	    )
	    pics.append (tn)
	    page.linksToFix.append (tn.href)
	    page.imagesToFix.append (tn.img)
	
	list.append (apply (ThumbnailTable, pics))
	return list
	    
    # Read all screenshots and sort them by date.
    dirs = glob.glob (os.path.join (screenshoturl, '[0-9]*'))
    dirs.sort ()
    dirs.reverse ()
    for dir in dirs:
	page.extend (processDir (dir))

    page.write ()

import links

def genDownload ():
    page = PageMeat ('Downloads', 'download.html')
    # Create the page for downloads
    page.extend ([
	Heading (2, 'Downloads'),
	Paragraph ('Some places where you can find files related to AROS:'),
    ])
    page.append (processLinks (links.downloadLinks))
    page.write ()

def genSnapshots ():
    '''Create the page with the snapshots with sizes and links for
    download.'''
    page = PageMeat ('Snapshots', 'snapshots.html')
    page.append (
	Heading (2, "Snapshots"),
    )

    files = glob.glob (os.path.join (ftpdir, 'snapshots/*.tgz'))
    if not files:
        page.append (
	    Text ('No snapshots found')
	)
    else:
	dict = {}
	columns = {}
	days = {}

	for file in files:
	    ss = Snapshot (file)
	    day = dict.get (ss.date, None)
	    if not day:
		day = {}
		dict[ss.date] = day
	    if ss.ext != 'tgz':
		print 'Unknown Snapshot', file
		continue

	    day[ss.title] = ss
	    columns[ss.title] = None
	    days[ss.date] = None
	
	table = TableLite (cellpadding=15, border=2)
	page.append (table)
	
	colList = columns.keys ()
	colList.sort ()
	row = TR ()
	table.append (row)
	td = TH ('Date')
	row = row + [td]
	    
	for col in colList:
	    td = TH (col)
	    row = row + [td]
	
	dateList = days.keys ()
	dateList.sort ()
	dateList.reverse ()
	for date in dateList:
	    row = TR ()
	    table.append (row)

	    str = '%d.%d.%d' % (
		int (date[6:8]),
		int (date[4:6]),
		int (date[0:4]),
	    )
	    row = row + [TD (str)]

	    day = dict.get (date, {})

	    for col in colList:
		t = Text ()
		ss = day.get (col, None)
		if ss:
		    t.append (Href ('ftp://ftp.aros.org/pub/aros/snapshots/%s' % ss.filename,
			ss.size
		    ))
		
		    if ss.log:
			t.append ('(Log: ')
			t.append (Href (
			    'ftp://ftp.aros.org/pub/aros/snapshots/%s' % \
				ss.log.filename,
			    ss.log.size
			))
			t.append (')')
		    else:
			if not ss.title in ('contrib', 'source'):
			    t.append ('(No log)')
		else:
		    t.append ('-')

		row = row + [TD (t)]

    page.write ()

def processLinks (links):
    list = List ()

    for link in links:
	if type (link) == type (()):
	    link, children = link[0], link[1:]
	else:
	    children = None

	text = Text (link.href)
	if link.text:
	    if type (link.text) == type (()):
		t = Text ()
		for item in link.text:
		    t.append (item)
	    else:
		t = Text (link.text)
	    text.append (t)
	if link.logo:
	    text.append (Image ((link.logo)))

	list.append (text)
	
	if children:
	    sublist = processLinks (children)
	    list.append (sublist)
    
    return list

def genLinks ():
    '''Create a page with links from links.py.'''
    def processSection (links, title):
	body = []

	#print title, list

	body.append (Name (title))
	body.append (Heading (2, title))
	try:
	    list = processLinks (links)
	except:
	    print 'processSection',title
	    raise
	body.append (list)

	return body

    page = PageMeat ('Links', 'links.html')
    page.append (
	Href ('#Mirrors', 'Mirrors'),
	BR(),
	Href ('#More Related', 'More Related'),
	BR(),
	Href ('#Articles', 'Articles'),
	BR(),
	Href ('#Homepages', 'Homepages'),
	BR(),
	Href ('#Less Related', 'Less Related'),
	BR(),
	BR(), HR(), BR(),
    )

    page.extend (processSection (links.mirrors, 'Mirrors'))
    page.extend (processSection (links.moreRelated, 'More Related'))
    page.extend (processSection (links.articles, 'Articles'))
    page.extend (processSection (links.homepages, 'Homepages'))
    page.extend (processSection (links.lessRelated, 'Less Related'))

    page.write ()

import xml2html, xmlsupport

class XmlPageMeat (PageMeat):
    def __init__ (self, key, url, xmlfilename):
	PageMeat.__init__ (self, key, url)

	xmlfile = xmlsupport.AROSXmlFile ()

	XML2HTML = xml2html.Xml2HtmlProcessor ()
	XML2HTML.toccount = [0, 0, 0, 0, 0]
	XML2HTML.toc = []

	xmlfile.parse (xmlfilename)
	xmlfile.process (XML2HTML)
	if XML2HTML.toc:
	    self.extend (XML2HTML.toc)
	    self.extend ([BR(), HR (), BR()])
	self.append (RawText (XML2HTML.fh.getvalue ()))
	XML2HTML.fh.close ()

docsrcdir = os.path.join (arosdir, 'docs', 'src')
def DocSrcDir (path):
    return os.path.join (docsrcdir, path)

def genPartialXmlPage (key, basename):
    xmlfilename = DocSrcDir(basename+'.xml')
    pp = XmlPageMeat (key, basename+'.html', xmlfilename)
    pp.write ()

def genPartialFAQ ():
    import faq

    faqobj = faq.FAQ (os.path.join (arosdir, 'docs', 'faq'),)
    xml = faqobj.toXml ()

    pm = PageMeat ('Documentation/FAQ', 'faq.html')
    pm.extend (xml2html.elementToHtml (xml))
    pm.write ()
    
# Call all generators in turn
import news
news.gen (datadir)

import status
status.gen (PageMeat)

genDocumentation ()
genPartialXmlPage ('Documentation/Background', 'background')
genPartialFAQ ()
genPartialXmlPage ('Documentation/CVS', 'cvs')
genPartialXmlPage ('Documentation/MetaMake', 'mmake')
genPartialXmlPage ('Documentation/Coding Style', 'style')
genPartialXmlPage ('Documentation/AROS XML', 'xml')
genPartialXmlPage ('Documentation/Filesystems', 'filesys')
genPartialXmlPage ('Documentation/HIDD Intro', 'hidd-intro')
genPartialXmlPage ('Documentation/HIDD Model', 'hidd-model')

import contents2html
contents2html.gen (PageMeat)

import htmlautodocs
htmlautodocs.gen ()

genPartialXmlPage ('Documentation/Random Ideas', 'ideas')

node = mainLinks2.findNode ('Documentation/AutoDocs')
node.order.sort ()
#print node,node.order

genScreenshots ()
genDownload ()
genSnapshots ()
genLinks ()

processPartialPages ()

